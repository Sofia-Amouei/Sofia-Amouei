{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOzkfQygc7T1YSSE5d6PLeN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sofia-Amouei/Sofia-Amouei/blob/main/Machine_Translations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "##Prepared by **\"Sofia Amouei 4013074508, Machine Translations\"**\n",
        "## Text mining & Web mining Course Project, Decision Science & Computer Engineering student, Khorazmi University; January 11, 2024"
      ],
      "metadata": {
        "id": "Ptm9ESEJFK5f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Extracting Python codes for Rule-Based machine translation (RBMT), Statistical Machine Translation (SMT), and Neural Machine Translation (NMT) systems requires reviewing various sources, as these are complex systems developed over many years by numerous researchers and engineers. In this research, each translation system was examined separately for English and Spanish languages and their codes were analyzed in this Colab:*"
      ],
      "metadata": {
        "id": "vP8BbxozGhBq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1-Rule-Based Machine Translation (RBMT):**\n",
        "\n",
        "These systems are an early form of machine translation technology that rely heavily on linguistic rules and dictionaries. Unlike modern statistical or neural machine translation systems, RBMT focuses on translating texts by applying grammatical and syntactic rules of the source and target languages. These rules are typically handcrafted by linguists.\n",
        "\n",
        "To create a simple example of an RBMT system, let's consider a basic Python script for translating a very limited set of sentences from **English to Spanish**. This system will be highly simplified and will not represent the complexity found in full-scale RBMT systems."
      ],
      "metadata": {
        "id": "3mm_VH6Zg9vo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A Simple Rule-Based Machine Translation Example: English to Spanish\n",
        "\n",
        "# Dictionary for word-to-word translation\n",
        "english_to_spanish_dict = {\n",
        "    \"cat\": \"gato\",\n",
        "    \"dog\": \"perro\",\n",
        "    \"eats\": \"come\",\n",
        "    \"sleeps\": \"duerme\",\n",
        "    \"the\": \"el\"  # Assuming only masculine nouns for simplicity\n",
        "}\n",
        "\n",
        "# Simple rules for sentence structure\n",
        "# English: Subject-Verb-Object\n",
        "# Spanish: Subject-Object-Verb\n",
        "\n",
        "def translate_sentence(sentence):\n",
        "    words = sentence.lower().split()\n",
        "    translated_words = []\n",
        "\n",
        "    if len(words) == 3:  # Simple sentences with Subject, Verb, Object\n",
        "        subject, verb, obj = words\n",
        "        # Translate each word\n",
        "        subject_spanish = english_to_spanish_dict.get(subject, \"UNKNOWN\")\n",
        "        verb_spanish = english_to_spanish_dict.get(verb, \"UNKNOWN\")\n",
        "        object_spanish = english_to_spanish_dict.get(obj, \"UNKNOWN\")\n",
        "\n",
        "        # Reorder words to fit Spanish structure: Subject-Object-Verb\n",
        "        translated_words = [subject_spanish, object_spanish, verb_spanish]\n",
        "\n",
        "    return ' '.join(translated_words)\n",
        "\n",
        "# Example usage\n",
        "english_sentence = \"The cat eats\"\n",
        "spanish_translation = translate_sentence(english_sentence)\n",
        "print(f\"English: {english_sentence} | Spanish: {spanish_translation}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5L-suwQ4iphH",
        "outputId": "c2d539cc-ea27-493f-d291-f0e44e934441"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English: The cat eats | Spanish: el come gato\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code is a basic representation and works only for very specific sentence structures. Real-world RBMT systems are far more complex and involve extensive rules for grammar, syntax, and context handling. They may also include morphological analysis, part-of-speech tagging, and other linguistic processes. The development of such systems requires deep linguistic expertise and extensive language-specific development."
      ],
      "metadata": {
        "id": "B0p1zHRGj1wB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2-Statistical Machine Translation (SMT):**\n",
        "\n",
        "Statistical Machine Translation (SMT) is a type of machine translation that uses statistical models to translate text from one language to another. Unlike Rule-Based Machine Translation (RBMT), which relies on linguistic rules, SMT learns to translate by analyzing large volumes of bilingual text data. The core idea is to find patterns and probabilities of words and phrases in one language corresponding to those in another.\n",
        "\n",
        "SMT typically involves the following components:\n",
        "\n",
        "**1-Language Model:** Determines the probability of a sequence of words in the target language.\n",
        "\n",
        "**2-Translation Model:** Determines the probability of a source language phrase translating to a target language phrase.\n",
        "\n",
        "**3-Decoder:** Finds the best translation by combining probabilities from the language and translation models.\n",
        "\n",
        "Creating a full-fledged SMT system from scratch is complex and requires extensive data and computational resources. However,\n",
        "we can provide a simplified Python example to illustrate the basic concept.\n",
        "\n",
        "In this example, we'll use a small predefined dictionary for phrase translations and a simple model **(English to Spanish)** for choosing translations based on probabilities."
      ],
      "metadata": {
        "id": "sYLsmZY2kYFI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# Example Translation Model: A simple dictionary with probabilities\n",
        "# Format: { \"source phrase\": [(translation, probability), ...]}\n",
        "translation_model = {\n",
        "    \"hello\": [(\"hola\", 0.6), (\"buenos d√≠as\", 0.4)],\n",
        "    \"world\": [(\"mundo\", 1.0)],\n",
        "}\n",
        "\n",
        "# Example Language Model: Function to randomly choose a translation based on probabilities\n",
        "def choose_translation(phrase):\n",
        "    if phrase in translation_model:\n",
        "        translations = translation_model[phrase]\n",
        "        total = sum(prob for _, prob in translations)\n",
        "        rand = random.uniform(0, total)\n",
        "        current = 0\n",
        "        for translation, prob in translations:\n",
        "            current += prob\n",
        "            if rand <= current:\n",
        "                return translation\n",
        "    return \"UNKNOWN\"\n",
        "\n",
        "# Example Decoder: Function to translate a sentence\n",
        "def translate_sentence(sentence):\n",
        "    translated_sentence = []\n",
        "    for word in sentence.lower().split():\n",
        "        translated_sentence.append(choose_translation(word))\n",
        "    return ' '.join(translated_sentence)\n",
        "\n",
        "# Example usage\n",
        "english_sentence = \"hello world\"\n",
        "spanish_translation = translate_sentence(english_sentence)\n",
        "print(f\"English: {english_sentence} | Spanish: {spanish_translation}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIpBWsTrsn_r",
        "outputId": "ead8bbfb-92fc-47c1-a20f-1a9c6244d1a2"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English: hello world | Spanish: hola mundo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code is a very basic illustration and does not represent the complexity and sophistication of actual SMT systems. Real SMT systems, like those used by Google Translate in its early years, involve training on large bilingual corpora, sophisticated probabilistic models, and complex algorithms for decoding and translation. SMT has largely been surpassed by Neural Machine Translation (NMT) models in recent years, which offer improvements in translation quality and efficiency."
      ],
      "metadata": {
        "id": "4CTnGXONtLk-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3-Neural Machine Translation (NMT):**\n",
        "Neural Machine Translation (NMT) is a sophisticated approach to machine translation that utilizes deep neural networks, particularly **sequence-to-sequence (seq2seq) models**. These models have significantly improved the quality of machine translation by effectively handling long-range dependencies and nuances in language. NMT systems are trained on large bilingual datasets and learn to translate by finding complex patterns in the data.\n",
        "A full-fledged NMT system is complex and requires substantial computational resources for training. However, We can provide a simplified Python example using the **Hugging Face Transformers** library, which includes pre-trained NMT models. This example will demonstrate how to use a pre-trained NMT model for translating text from **English to Spanish**."
      ],
      "metadata": {
        "id": "JRS1SoqztR99"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install sentencepiece\n",
        "import sentencepiece as spm\n",
        "spm.SentencePieceProcessor()\n",
        "from transformers import pipeline\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpdA9Ye-1woM",
        "outputId": "c8ea2964-f893-4467-ecd0-06a6f5fe2c30"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.36.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install googletrans==4.0.0-rc1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdzyJDtO7ALG",
        "outputId": "eb86788b-2927-4ae1-91ad-e4f2fdca2d1f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: googletrans==4.0.0-rc1 in /usr/local/lib/python3.10/dist-packages (4.0.0rc1)\n",
            "Requirement already satisfied: httpx==0.13.3 in /usr/local/lib/python3.10/dist-packages (from googletrans==4.0.0-rc1) (0.13.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2023.11.17)\n",
            "Requirement already satisfied: hstspreload in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2024.1.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.3.0)\n",
            "Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.4)\n",
            "Requirement already satisfied: idna==2.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2.10)\n",
            "Requirement already satisfied: rfc3986<2,>=1.3 in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.5.0)\n",
            "Requirement already satisfied: httpcore==0.9.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.1)\n",
            "Requirement already satisfied: h11<0.10,>=0.8 in /usr/local/lib/python3.10/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.0)\n",
            "Requirement already satisfied: h2==3.* in /usr/local/lib/python3.10/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.2.0)\n",
            "Requirement already satisfied: hyperframe<6,>=5.2.0 in /usr/local/lib/python3.10/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (5.2.0)\n",
            "Requirement already satisfied: hpack<4,>=3.0 in /usr/local/lib/python3.10/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from googletrans import Translator, LANGUAGES\n",
        "\n",
        "# Initialize the Google Translate API translator\n",
        "translator = Translator()\n",
        "\n",
        "# Translate text from English to Spanish\n",
        "english_text = \"This is an example of neural machine translation.\"\n",
        "translated = translator.translate(english_text, src='en', dest='es')\n",
        "\n",
        "print(f\"English: {english_text} | Spanish: {translated.text}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1OC7ZGL7Lql",
        "outputId": "e3f9ba34-f92b-4a95-aaac-4f3f4754869e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English: This is an example of neural machine translation. | Spanish: Este es un ejemplo de traducci√≥n al autom√≥vil neural.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this code:\n",
        "We create an instance of Translator from the googletrans library.\n",
        "We then use the translate method to translate the given **English text to Spanish**, specifying **src='en'** for source language and **dest='es'** for destination language.\n",
        "Finally, we print the original English text and its Spanish translation.\n",
        "This approach should work more smoothly, as it doesn't require complex model setups or external dependencies beyond the googletrans library itself."
      ],
      "metadata": {
        "id": "SN8sKOas74nZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Machine translation is a vibrant area of research and development, and GitHub hosts a variety of projects ranging from academic prototypes to industry-grade frameworks. Here are some notable GitHub repositories in the field of machine translation:\n",
        "\n",
        "**1-T2T (Tensor2Tensor) by Google Research:**\n",
        "Repository: github.com/tensorflow/tensor2tensor\n",
        "\n",
        "Description: Tensor2Tensor is a library for deep learning models and datasets designed by Google Research. It includes implementations of many state-of-the-art models, including those for machine translation.\n",
        "\n",
        "**2-OpenNMT:**\n",
        "Repository: github.com/OpenNMT\n",
        "\n",
        "Description: OpenNMT is an open-source ecosystem for neural machine translation and neural sequence learning. Started at Harvard, it has been developed and maintained by a wide range of contributors. OpenNMT provides implementations in both PyTorch (OpenNMT-py) and TensorFlow (OpenNMT-tf).\n",
        "\n",
        "**3-Marian NMT:**\n",
        "Repository: github.com/marian-nmt/marian\n",
        "\n",
        "Description: Marian is an efficient, free Neural Machine Translation framework mainly being developed by the Microsoft Translator team. It is particularly geared towards translation, but can be used for any sequence-to-sequence tasks.\n",
        "\n",
        "**4-Fairseq by Facebook AI Research:**\n",
        "Repository: github.com/pytorch/fairseq\n",
        "\n",
        "Description: Fairseq is a sequence-to-sequence learning toolkit from Facebook AI Research that allows researchers and developers to train custom models for translation, summarization, language modeling, and other text generation tasks.\n",
        "\n",
        "**5-Transformers by Hugging Face:**\n",
        "Repository: github.com/huggingface/transformers\n",
        "\n",
        "Description: Although not exclusively for machine translation, this library provides general-purpose architectures for natural language understanding and generation. It includes many pre-trained models that can be used for machine translation.\n",
        "\n",
        "**6-Joey NMT:**\n",
        "Repository: github.com/joeynmt/joeynmt\n",
        "\n",
        "Description: Joey NMT is a minimalist NMT toolkit for educational purposes. It's designed to be simple, transparent, and easy to modify and extend.\n",
        "\n",
        "**7-T5 (Text-To-Text Transfer Transformer) by Google Research:**\n",
        "Repository: github.com/google-research/text-to-text-transfer-transformer\n",
        "\n",
        "Description: T5 reframes all NLP tasks as a text-to-text problem, and it provides a unified framework that can be used for translation, summarization, question answering, and other tasks.\n",
        "These projects represent a mix of different approaches and are suitable for various levels of expertise, from beginners to advanced practitioners in machine learning and NLP.\n",
        "\n",
        "\"Thanks for your attention\""
      ],
      "metadata": {
        "id": "OOfTOkLMEKgG"
      }
    }
  ]
}